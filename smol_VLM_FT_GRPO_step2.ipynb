{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xiaodongeast/multimodal/blob/main/smol_VLM_FT_GRPO_step2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIBYTwXRbmQU"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate datasets peft bitsandbytes tensorboard\n",
        "!pip install -q flash-attn --no-build-isolation\n",
        "!pip install trl\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yR1hlq5K3HB7"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive6')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SYstsp8-cxqX"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "#\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18LXuVYQd3f7"
      },
      "outputs": [],
      "source": [
        "#from transformers import Idefics3ForConditionalGeneration,AutoProcessor\n",
        "#import torch\n",
        "#from peft import AutoPeftModel\n",
        "## merge base model and fine-tuned model\n",
        "#model_id =\"HuggingFaceTB/SmolVLM-Instruct\"\n",
        "#merged_model= AutoPeftModel.from_pretrained(\"/content/drive6/MyDrive/smolvlm-instruct-s4\")\n",
        "\n",
        "#processor = AutoProcessor.from_pretrained(\n",
        " #   model_id\n",
        "#)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_TOKN3eFF1Qh"
      },
      "outputs": [],
      "source": [
        "#merged_model = merged_model.merge_and_unload()\n",
        "#merged_model.save_pretrained(\"/content/drive6/MyDrive/smolvlm-instruct-s4merged\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLYjnl6vrwC1"
      },
      "outputs": [],
      "source": [
        "from transformers import Idefics3ForConditionalGeneration,AutoProcessor\n",
        "import torch\n",
        "from peft import AutoPeftModel\n",
        "## merge base model and fine-tuned model\n",
        "#model_id =\"HuggingFaceTB/SmolVLM-Instruct\"\n",
        "\n",
        "\n",
        "#processor = AutoProcessor.from_pretrained(\n",
        " #   model_id\n",
        "#)\n",
        "\n",
        "#model = Idefics3ForConditionalGeneration.from_pretrained(\n",
        "#\"/content/drive5/MyDrive/smolvlm-instruct-s4merged\"\n",
        "#)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "BASE = \"/content/drive5/MyDrive/smolvlm-instruct-s4merged\"   # your base model\n",
        "ADAPTER = \"/content/drive5/MyDrive/smolvlm-instruct-r1d\"         # <— put your adapter folder here\n",
        "OUT = \"/content/drive5/MyDrive/smolvlm-grpo-merged\"\n",
        "os.makedirs(OUT, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "4EdjOJVU6ZPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ACm-wKi7hXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoProcessor, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import os\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "\n",
        "# Pick a dtype that your device supports well\n",
        "dtype = torch.float16 if device in [\"cuda\",\"mps\"] else torch.float32\n",
        "\n",
        "base = Idefics3ForConditionalGeneration.from_pretrained(\n",
        "    BASE, torch_dtype=dtype, device_map=None\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "MPyEMh4p61td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach LoRA adapter\n",
        "model = PeftModel.from_pretrained(base, ADAPTER, is_trainable=False)\n",
        "\n",
        "# Merge LoRA weights into the base model\n",
        "merged = model.merge_and_unload(safe_merge=True).to(\"cpu\")"
      ],
      "metadata": {
        "id": "0SNj-ynb4WDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged.save_pretrained(OUT, safe_serialization=True)"
      ],
      "metadata": {
        "id": "zYnEnKNi4c-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged.push_to_hub(\"smolvlm-grpo-merged\")"
      ],
      "metadata": {
        "id": "8kdxpISO3ZBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWEWoqGueoPH"
      },
      "outputs": [],
      "source": [
        "# === GRPO dataset prep for SmolVLM / SmolVLM2 ===\n",
        "from typing import Dict, Any\n",
        "from PIL import Image\n",
        "\n",
        "# Use a consistent instruction; put it in the system message.\n",
        "instruct =\"\"\"Answer question about the image with your reasoning. Follow this format:\n",
        "<think>\n",
        "[Your detailed chain-of-thought goes here]\n",
        "</think>\n",
        "<answer>\n",
        "[Your final answer goes here]\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Make sure the tokenizer pads on the LEFT (important for GRPO).\n",
        "# (Some processors already set this; we enforce it to be safe.)\n",
        "processor.tokenizer.padding_side = \"left\"\n",
        "\n",
        "def _normalize_example(example: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"Converts input to: question(str), answer_text(str), image(PIL), thought(str or \"\"), choices(list|None).\"\"\"\n",
        "    img = example[\"image\"]\n",
        "    if isinstance(img, dict) and \"path\" in img:\n",
        "        img = Image.open(img[\"path\"]).convert(\"RGB\")\n",
        "    elif hasattr(img, \"mode\"):\n",
        "        if img.mode != \"RGB\":\n",
        "            img = img.convert(\"RGB\")\n",
        "    else:\n",
        "        img = Image.open(str(img)).convert(\"RGB\")\n",
        "\n",
        "    question = str(example.get(\"question\", \"\")).strip()\n",
        "\n",
        "    if \"multiple_choice_answer\" in example and example[\"multiple_choice_answer\"] is not None:\n",
        "        answer_text = str(example[\"multiple_choice_answer\"]).strip()\n",
        "    else:\n",
        "        choices = example.get(\"choices\")\n",
        "        ans_idx = example.get(\"answer\")\n",
        "        if isinstance(ans_idx, int) and isinstance(choices, list) and 0 <= ans_idx < len(choices):\n",
        "            answer_text = str(choices[ans_idx]).strip()\n",
        "        else:\n",
        "            answer_text = str(example.get(\"answer\", \"\")).strip()\n",
        "\n",
        "    thought = str(example.get(\"solution\", \"\") or \"\").strip()\n",
        "    return {\n",
        "        \"image\": img,\n",
        "        \"question\": question,\n",
        "        \"answer_text\": answer_text,\n",
        "        \"thought\": thought,\n",
        "        \"choices\": example.get(\"choices\")\n",
        "    }\n",
        "\n",
        "def format_grpo_example(raw_ex: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Build a GRPO training row:\n",
        "      - prompt: chat-templated text with <image> token and NO assistant target\n",
        "      - image: PIL image\n",
        "      - answer_text: kept for accuracy rewards\n",
        "      - choices: optional passthrough\n",
        "    \"\"\"\n",
        "    exn = _normalize_example(raw_ex)\n",
        "    #print(exn)\n",
        "\n",
        "    messages = [\n",
        "\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\"type\": \"image\"},\n",
        "                {\"type\": \"text\", \"text\":instruct + '\\n' + 'Querstion:\\n' + exn[\"question\"]}\n",
        "               # {\"type\": \"text\", \"text\": },\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # IMPORTANT: add_generation_prompt=True → the prompt ends where assistant should start generating\n",
        "    prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "\n",
        "    return {\n",
        "        \"prompt\": prompt,\n",
        "        \"image\": exn[\"image\"],\n",
        "        \"answer_text\": exn[\"answer_text\"],\n",
        "        #\"choices\": exn[\"choices\"],  # optional passthrough\n",
        "        # You can keep other metadata if you like (ids, source, etc.)\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnU3sq_UexGE"
      },
      "outputs": [],
      "source": [
        "#train_ds = split_ds[\"train\"]\n",
        "from datasets import load_dataset\n",
        "from datasets import concatenate_datasets, DatasetDict\n",
        "from huggingface_hub import notebook_login\n",
        "ds = load_dataset((\"bugkiller2025/vqa_reasoning\"))\n",
        "train_ds = ds['train']\n",
        "eval_ds = ds['eval']\n",
        "test_ds = ds['test']\n",
        "train_ds = train_ds.map(format_grpo_example)\n",
        "train_ds = train_ds.remove_columns([  \"question\", \"answer\", \"choices\", \"question_type\",\"answer_type\",\"image_organ\" ,\"solution\",'phrase_type'])\n",
        "print(train_ds)\n",
        "print(train_ds[0]['prompt'])\n",
        "train_ds[0]['image']\n",
        "train_ds[0]['answer_text']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHVscPJ0paik"
      },
      "outputs": [],
      "source": [
        "# make sure model and data are correct\n",
        "import matplotlib.pyplot as plt\n",
        "example =  train_ds[12]\n",
        "print(example)\n",
        "plt.imshow(example['image'])\n",
        "model.to('cuda')\n",
        "\n",
        "model_inputs= processor(text=[example['prompt']], images=[example['image']], return_tensors=\"pt\", padding=True).to('cuda')\n",
        "# Generate predictions\n",
        "with torch.no_grad():\n",
        "  outputs = model.generate(**model_inputs,max_new_tokens =200)\n",
        "trimmed_generated_ids = [out_ids[len(in_ids) :] for in_ids, out_ids in zip( model_inputs.input_ids, outputs)]\n",
        "\n",
        "\n",
        "# Decode the prediction\n",
        "prediction = processor.batch_decode(  trimmed_generated_ids, skip_special_tokens=True)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4erQmP3We0dO"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "import string\n",
        "from typing import List, Union\n",
        "\n",
        "def _format_reward(text):\n",
        "\n",
        "    # now if complete match\n",
        "    pattern_strict = r'^\\s*<think>.*?</think>\\s*?\\n*\\s*?<answer>.*?</answer>\\s*$'\n",
        "\n",
        "    match_strict = re.match(pattern_strict, text, re.DOTALL | re.MULTILINE)\n",
        "    if match_strict:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "print(_format_reward('<think> something </think>. '))\n",
        "input2 = '  <answer>yes</answer>'\n",
        "input3 =' www <think>gkkkk</think> \\n <answer>ssss</answer>'\n",
        "input4 =' <think>gkkkk</think> \\n <answer>ssss</answer> '\n",
        "input5 =' <think>\\nThe enhanced muscles look normal in comparison to other structures of the brain.\\n</think>\\n<answer>\\nNo.'\n",
        "print(_format_reward(input2))\n",
        "print(_format_reward(input3))\n",
        "print(_format_reward(input4))\n",
        "print(_format_reward(input5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def format_reward(completions, **kwargs):\n",
        "    \"\"\"format: Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    completion_contents = [completion for completion in completions]\n",
        "    rewards = [_format_reward(text) for text in completion_contents]\n",
        "    #print('format rewards',rewards)\n",
        "    return rewards\n",
        "\n",
        "\n",
        "# --- helper: extract only the <answer>...</answer> block if present ---\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    if ('<answer>' not in text) or ('</answer>' not in text):\n",
        "        return ''\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    answer = _normalize_label(answer.strip())\n",
        "    return answer\n",
        "\n",
        "def extract_xml_think(text: str) -> str:\n",
        "    if ('<think>' not in text) or ('</think>' not in text):\n",
        "        return ''\n",
        "    think = text.split(\"<think>\")[-1]\n",
        "    think = think.split(\"</think>\")[0]\n",
        "    return think.strip()\n",
        "\n",
        "\n",
        "# --- helper: plain-text normalization for the fallback path (yes/no, categories) ---\n",
        "\n",
        "\n",
        "# Optional: small synonym map for yes/no style answers\n",
        "_YN = {\"yes\": {\"yes\", \"y\", \"true\", \"correct\"}, \"no\": {\"no\", \"n\", \"false\", \"incorrect\"}}\n",
        "def _normalize_label(s: str) -> str:\n",
        "    if s.lower() in _YN[\"yes\"]:\n",
        "        return \"yes\"\n",
        "    elif s.lower() in _YN[\"no\"]:\n",
        "        return \"no\"\n",
        "    else:\n",
        "        return s\n",
        "\n",
        "\n",
        "# - reward function\n",
        "def _count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"<think>\") == 1:\n",
        "        count += 0.1 # think use 0.25 for all we try to increase for thnk\n",
        "    if text.count(\"</think>\") == 1:\n",
        "        count += 0.1\n",
        "    if text.count(\"<answer>\") == 1:\n",
        "        count += 0.1\n",
        "    if text.count(\"</answer>\") == 1:\n",
        "        count += 0.1\n",
        "    return count\n",
        "\n",
        "def _think_reward(text) ->float: # 570+/- 180 this is perfered length\n",
        "    # we linearly increase to encourage the length\n",
        "    if 0 < len(text) < 400:\n",
        "        return  1.0* len(text) / 400.0 # if 40chr reward 0.1  400char 1\n",
        "    if  400< len(text) <750 : # previous cut for 750\n",
        "        return 1.0\n",
        "    if len(text) >750:\n",
        "        return 0.25 # bonus for think something\n",
        "    else:\n",
        "      return 0.0\n",
        "\n",
        "print(_think_reward(input5))\n",
        "print(_think_reward(input3))\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    try:\n",
        "      completion_contents = [completion for completion in completions]\n",
        "    except Exception as e:\n",
        "      completion_contents = [completion[0]['content'] for completion in completions]\n",
        "    rewards = [_count_xml(c) for c in completion_contents ]\n",
        "\n",
        "\n",
        "    return rewards\n",
        "\n",
        "\n",
        "def think_length_reward_func(completions, **kwargs)  -> list[float]:\n",
        "    # get think\n",
        "    try:\n",
        "      completion_contents = [completion for completion in completions]\n",
        "    except Exception as e:\n",
        "      completion_contents = [completion[0]['content'] for completion in completions]\n",
        "    extracted_think = [extract_xml_think(r) for r in completion_contents ]\n",
        "    rewards = [_think_reward(r) for r in extracted_think ]\n",
        "\n",
        "    return rewards\n",
        "\n",
        "\n",
        "def accuracy_reward( completions, **kwargs) -> list[float]:\n",
        "    answer_text =  kwargs['answer_text']\n",
        "    completion_contents = [completion for completion in completions]\n",
        "    extracted_responses = [extract_xml_answer(r) for r in completion_contents ]\n",
        "    #print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    reward = [1.0 if r == a.strip() else 0.0 for r, a in zip(extracted_responses, answer_text)]\n",
        "\n",
        "    return reward\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDMwUdZJe34Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from trl import GRPOConfig\n",
        "\n",
        "\n",
        "# merge\n",
        "\n",
        "\n",
        "# Configure training arguments using GRPOConfig\n",
        "training_args = GRPOConfig(\n",
        "    output_dir=\"/content/drive5/MyDrive/smolvlm-r1d\",\n",
        "    learning_rate=1e-5,\n",
        "    remove_unused_columns=False,  # to access the solution column in accuracy_reward\n",
        "    num_train_epochs=1,\n",
        "    bf16=True,\n",
        "    # Parameters that control the data preprocessing\n",
        "    per_device_train_batch_size= 8,\n",
        "    max_completion_length=1024,  # default: 256\n",
        "    num_generations= 8,  # default: 8\n",
        "    max_prompt_length=None,\n",
        "    # Parameters related to reporting and saving\n",
        "    report_to=[\"tensorboard\"],\n",
        "    logging_steps=10,\n",
        "\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=10,\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "model = get_peft_model( model, lora_config)\n",
        "\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "satjNnsyio1H"
      },
      "outputs": [],
      "source": [
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    processing_class=processor,\n",
        "    reward_funcs=[accuracy_reward,format_reward,  think_length_reward_func ],\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "luFHJLALfIAT"
      },
      "outputs": [],
      "source": [
        "trainer.train()\n",
        "trainer.save_model(\"/content/drive5/MyDrive/smolvlm-instruct-r1d\")\n",
        "trainer.push_to_hub(\"smolvlm-instruct-r1d\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMl3IBV1DbMQ"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"/content/drive5/MyDrive/smolvlm-instruct-r1e\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Idefics3ForConditionalGeneration,AutoProcessor\n",
        "import torch\n",
        "from peft import AutoPeftModel\n",
        "model = Idefics3ForConditionalGeneration.from_pretrained(\n",
        "\"/content/drive5/MyDrive/smolvlm-instruct-r1e\"\n",
        ")"
      ],
      "metadata": {
        "id": "rOk3uHdsN3tK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMhoKdFmZ0OLMIZI5TdaSv+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}